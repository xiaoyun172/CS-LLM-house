<!DOCTYPE html>
<html lang="zh">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cherry Studio ASR</title>
    <style>
        body {
            font-family: sans-serif;
            padding: 1em;
        }

        #status {
            margin-top: 1em;
            font-style: italic;
            color: #555;
        }

        #result {
            margin-top: 0.5em;
            border: 1px solid #ccc;
            padding: 0.5em;
            min-height: 50px;
            background: #f9f9f9;
        }
    </style>
</head>

<body>
    <h1>æµè§ˆå™¨è¯­éŸ³è¯†åˆ«ä¸­ç»§é¡µé¢</h1>
    <p>è¿™ä¸ªé¡µé¢éœ€è¦åœ¨æµè§ˆå™¨ä¸­ä¿æŒæ‰“å¼€ï¼Œä»¥ä¾¿åº”ç”¨ä½¿ç”¨å…¶è¯­éŸ³è¯†åˆ«åŠŸèƒ½ã€‚</p>
    <div id="status">æ­£åœ¨è¿æ¥åˆ°æœåŠ¡å™¨...</div>
    <div id="result"></div>

    <script>
        const statusDiv = document.getElementById('status');
        const resultDiv = document.getElementById('result');
        // å°è¯•è¿æ¥åˆ°WebSocketæœåŠ¡å™¨
        let ws;
        let reconnectAttempts = 0;
        const maxReconnectAttempts = 5;
        const reconnectInterval = 2000; // 2ç§’

        function connectWebSocket() {
            try {
                ws = new WebSocket('ws://localhost:34515');

                ws.onopen = () => {
                    reconnectAttempts = 0;
                    updateStatus('å·²è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œç­‰å¾…æŒ‡ä»¤...');
                    ws.send(JSON.stringify({ type: 'identify', role: 'browser' }));
                };

                ws.onmessage = handleMessage;

                ws.onerror = (error) => {
                    console.error('[Browser Page] WebSocket Error:', error);
                    updateStatus('WebSocket è¿æ¥é”™è¯¯ï¼è¯·æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦è¿è¡Œã€‚');
                };

                ws.onclose = () => {
                    console.log('[Browser Page] WebSocket Connection Closed');
                    updateStatus('ä¸æœåŠ¡å™¨æ–­å¼€è¿æ¥ã€‚å°è¯•é‡æ–°è¿æ¥...');
                    stopRecognition();

                    // å°è¯•é‡æ–°è¿æ¥
                    if (reconnectAttempts < maxReconnectAttempts) {
                        reconnectAttempts++;
                        updateStatus(`ä¸æœåŠ¡å™¨æ–­å¼€è¿æ¥ã€‚å°è¯•é‡æ–°è¿æ¥ (${reconnectAttempts}/${maxReconnectAttempts})...`);
                        setTimeout(connectWebSocket, reconnectInterval);
                    } else {
                        updateStatus('æ— æ³•è¿æ¥åˆ°æœåŠ¡å™¨ã€‚è¯·åˆ·æ–°é¡µé¢æˆ–é‡å¯åº”ç”¨ã€‚');
                    }
                };
            } catch (error) {
                console.error('[Browser Page] Error creating WebSocket:', error);
                updateStatus('åˆ›å»ºWebSocketè¿æ¥æ—¶å‡ºé”™ã€‚è¯·åˆ·æ–°é¡µé¢æˆ–é‡å¯åº”ç”¨ã€‚');
            }
        }

        // åˆå§‹è¿æ¥
        connectWebSocket();
        let recognition = null;
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

        function updateStatus(message) {
            console.log(`[Browser Page Status] ${message}`);
            statusDiv.textContent = message;
        }

        function handleMessage(event) {
            let data;
            try {
                data = JSON.parse(event.data);
                console.log('[Browser Page] Received command:', data);
            } catch (e) {
                console.error('[Browser Page] Received non-JSON message:', event.data);
                return;
            }

            if (data.type === 'start') {
                startRecognition();
            } else if (data.type === 'stop') {
                stopRecognition();
            } else if (data.type === 'reset') {
                // å¼ºåˆ¶é‡ç½®è¯­éŸ³è¯†åˆ«
                forceResetRecognition();
            } else {
                console.warn('[Browser Page] Received unknown command type:', data.type);
            }
        };



        function setupRecognition() {
            if (!SpeechRecognition) {
                updateStatus('é”™è¯¯ï¼šæ­¤æµè§ˆå™¨ä¸æ”¯æŒ Web Speech APIã€‚');
                return false;
            }
            if (recognition && recognition.recognizing) {
                console.log('[Browser Page] Recognition already active.');
                return true;
            }

            recognition = new SpeechRecognition();
            recognition.lang = 'zh-CN';
            recognition.continuous = true;
            recognition.interimResults = true;
            // å¢åŠ ä»¥ä¸‹è®¾ç½®æé«˜è¯­éŸ³è¯†åˆ«çš„å¯é æ€§
            recognition.maxAlternatives = 3; // è¿”å›å¤šä¸ªå¯èƒ½çš„è¯†åˆ«ç»“æœ
            // è®¾ç½®è¾ƒçŸ­çš„è¯­éŸ³è¯†åˆ«æ—¶é—´ï¼Œä½¿ç”¨æˆ·èƒ½æ›´å¿«åœ°çœ‹åˆ°ç»“æœ
            // æ³¨æ„ï¼šè¿™ä¸ªå±æ€§ä¸æ˜¯æ ‡å‡†çš„ï¼Œå¯èƒ½ä¸æ˜¯æ‰€æœ‰æµè§ˆå™¨éƒ½æ”¯æŒ
            try {
                // @ts-ignore
                recognition.audioStart = 0.1; // å°è¯•è®¾ç½®è¾ƒä½çš„èµ·å§‹éŸ³é‡é˜ˆå€¼
            } catch (e) {
                console.log('[Browser Page] audioStart property not supported');
            }

            recognition.onstart = () => {
                updateStatus("ğŸ¤ æ­£åœ¨è¯†åˆ«...");
                console.log('[Browser Page] SpeechRecognition started.');
            };

            recognition.onresult = (event) => {
                console.log('[Browser Page] Recognition result event:', event);

                let interim_transcript = '';
                let final_transcript = '';

                // è¾“å‡ºè¯†åˆ«ç»“æœçš„è¯¦ç»†ä¿¡æ¯ä¾¿äºè°ƒè¯•
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    const confidence = event.results[i][0].confidence;
                    console.log(`[Browser Page] Result ${i}: ${event.results[i][0].transcript} (Confidence: ${confidence.toFixed(2)})`);

                    if (event.results[i].isFinal) {
                        final_transcript += event.results[i][0].transcript;
                    } else {
                        interim_transcript += event.results[i][0].transcript;
                    }
                }

                const resultText = final_transcript || interim_transcript;
                resultDiv.textContent = resultText;

                // æ›´æ–°çŠ¶æ€æ˜¾ç¤º
                if (resultText) {
                    updateStatus(`ğŸ¤ æ­£åœ¨è¯†åˆ«... (å·²æ•æ‰åˆ°è¯­éŸ³)`);
                }

                if (ws.readyState === WebSocket.OPEN) {
                    console.log(`[Browser Page] Sending ${final_transcript ? 'final' : 'interim'} result to server:`, resultText);
                    ws.send(JSON.stringify({ type: 'result', data: { text: resultText, isFinal: !!final_transcript } }));
                }
            };

            recognition.onerror = (event) => {
                console.error(`[Browser Page] SpeechRecognition Error - Type: ${event.error}, Message: ${event.message}`);

                // æ ¹æ®é”™è¯¯ç±»å‹æä¾›æ›´å‹å¥½çš„é”™è¯¯æç¤º
                let errorMessage = '';
                switch (event.error) {
                    case 'no-speech':
                        errorMessage = 'æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œè¯·ç¡®ä¿éº¦å…‹é£å·¥ä½œæ­£å¸¸å¹¶å°è¯•è¯´è¯ã€‚';
                        // å°è¯•é‡æ–°å¯åŠ¨è¯­éŸ³è¯†åˆ«
                        setTimeout(() => {
                            if (recognition) {
                                try {
                                    recognition.start();
                                    console.log('[Browser Page] Restarting recognition after no-speech error');
                                } catch (e) {
                                    console.error('[Browser Page] Failed to restart recognition:', e);
                                }
                            }
                        }, 1000);
                        break;
                    case 'audio-capture':
                        errorMessage = 'æ— æ³•æ•è·éŸ³é¢‘ï¼Œè¯·ç¡®ä¿éº¦å…‹é£å·²è¿æ¥å¹¶å·²æˆæƒã€‚';
                        break;
                    case 'not-allowed':
                        errorMessage = 'æµè§ˆå™¨ä¸å…è®¸ä½¿ç”¨éº¦å…‹é£ï¼Œè¯·æ£€æŸ¥æƒé™è®¾ç½®ã€‚';
                        break;
                    case 'network':
                        errorMessage = 'ç½‘ç»œé”™è¯¯å¯¼è‡´è¯­éŸ³è¯†åˆ«å¤±è´¥ã€‚';
                        break;
                    case 'aborted':
                        errorMessage = 'è¯­éŸ³è¯†åˆ«è¢«ç”¨æˆ·æˆ–ç³»ç»Ÿä¸­æ­¢ã€‚';
                        break;
                    default:
                        errorMessage = `è¯†åˆ«é”™è¯¯: ${event.error}`;
                }

                updateStatus(`é”™è¯¯: ${errorMessage}`);

                if (ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({
                        type: 'error',
                        data: {
                            error: event.error,
                            message: errorMessage || event.message || `Recognition error: ${event.error}`
                        }
                    }));
                }
            };

            recognition.onend = () => {
                console.log('[Browser Page] SpeechRecognition ended.');

                // æ£€æŸ¥æ˜¯å¦æ˜¯ç”±äºé”™è¯¯æˆ–ç”¨æˆ·æ‰‹åŠ¨åœæ­¢å¯¼è‡´çš„ç»“æŸ
                const isErrorOrStopped = statusDiv.textContent.includes('é”™è¯¯') || statusDiv.textContent.includes('åœæ­¢');

                if (!isErrorOrStopped) {
                    // å¦‚æœä¸æ˜¯ç”±äºé”™è¯¯æˆ–æ‰‹åŠ¨åœæ­¢ï¼Œåˆ™è‡ªåŠ¨é‡æ–°å¯åŠ¨è¯­éŸ³è¯†åˆ«
                    updateStatus("è¯†åˆ«æš‚åœï¼Œæ­£åœ¨é‡æ–°å¯åŠ¨...");

                    // ä¿å­˜å½“å‰çš„recognitionå¯¹è±¡
                    const currentRecognition = recognition;

                    // å°è¯•é‡æ–°å¯åŠ¨è¯­éŸ³è¯†åˆ«
                    setTimeout(() => {
                        try {
                            if (currentRecognition && currentRecognition === recognition) {
                                currentRecognition.start();
                                console.log('[Browser Page] Automatically restarting recognition');
                            } else {
                                // å¦‚æœrecognitionå¯¹è±¡å·²ç»å˜åŒ–ï¼Œé‡æ–°åˆ›å»ºä¸€ä¸ª
                                setupRecognition();
                                if (recognition) {
                                    recognition.start();
                                    console.log('[Browser Page] Created new recognition instance and started');
                                }
                            }
                        } catch (e) {
                            console.error('[Browser Page] Failed to restart recognition:', e);
                            updateStatus("è¯†åˆ«å·²åœæ­¢ã€‚ç­‰å¾…æŒ‡ä»¤...");
                        }
                    }, 300);
                } else {
                    updateStatus("è¯†åˆ«å·²åœæ­¢ã€‚ç­‰å¾…æŒ‡ä»¤...");

                    if (ws.readyState === WebSocket.OPEN) {
                        ws.send(JSON.stringify({ type: 'status', message: 'stopped' }));
                    }

                    // åªæœ‰åœ¨æ‰‹åŠ¨åœæ­¢æˆ–é”™è¯¯æ—¶æ‰é‡ç½®recognitionå¯¹è±¡
                    recognition = null;
                }
            };
            return true;
        }

        function startRecognition() {
            if (!SpeechRecognition) {
                updateStatus('é”™è¯¯ï¼šæµè§ˆå™¨ä¸æ”¯æŒ Web Speech APIã€‚');
                return;
            }

            // æ˜¾ç¤ºæ­£åœ¨å‡†å¤‡çš„çŠ¶æ€
            updateStatus('æ­£åœ¨å‡†å¤‡éº¦å…‹é£...');

            if (recognition) {
                console.log('[Browser Page] Recognition already exists, stopping first.');
                stopRecognition();
            }

            if (!setupRecognition()) return;

            console.log('[Browser Page] Attempting to start recognition...');
            try {
                // è®¾ç½®æ›´é•¿çš„è¶…æ—¶æ—¶é—´ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„æ—¶é—´è·å–éº¦å…‹é£æƒé™
                const micPermissionTimeout = setTimeout(() => {
                    updateStatus('è·å–éº¦å…‹é£æƒé™è¶…æ—¶ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•ã€‚');
                }, 10000); // 10ç§’è¶…æ—¶

                navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                })
                    .then(stream => {
                        clearTimeout(micPermissionTimeout);
                        console.log('[Browser Page] Microphone access granted.');

                        // æ£€æŸ¥éº¦å…‹é£éŸ³é‡çº§åˆ«
                        const audioContext = new AudioContext();
                        const analyser = audioContext.createAnalyser();
                        const microphone = audioContext.createMediaStreamSource(stream);
                        const javascriptNode = audioContext.createScriptProcessor(2048, 1, 1);

                        analyser.smoothingTimeConstant = 0.8;
                        analyser.fftSize = 1024;

                        microphone.connect(analyser);
                        analyser.connect(javascriptNode);
                        javascriptNode.connect(audioContext.destination);

                        javascriptNode.onaudioprocess = function () {
                            const array = new Uint8Array(analyser.frequencyBinCount);
                            analyser.getByteFrequencyData(array);
                            let values = 0;

                            const length = array.length;
                            for (let i = 0; i < length; i++) {
                                values += (array[i]);
                            }

                            const average = values / length;
                            console.log('[Browser Page] Microphone volume level:', average);

                            // å¦‚æœéŸ³é‡å¤ªä½ï¼Œæ˜¾ç¤ºæç¤º
                            if (average < 5) {
                                updateStatus('éº¦å…‹é£éŸ³é‡å¾ˆä½ï¼Œè¯·è¯´è¯æˆ–æ£€æŸ¥éº¦å…‹é£è®¾ç½®ã€‚');
                            } else {
                                updateStatus('ğŸ¤ æ­£åœ¨è¯†åˆ«...');
                            }

                            // åªæ£€æŸ¥ä¸€æ¬¡å°±æ–­å¼€è¿æ¥
                            microphone.disconnect();
                            analyser.disconnect();
                            javascriptNode.disconnect();
                        };

                        // é‡Šæ”¾æµ‹è¯•ç”¨çš„éŸ³é¢‘æµ
                        setTimeout(() => {
                            stream.getTracks().forEach(track => track.stop());
                            audioContext.close();
                        }, 1000);

                        // å¯åŠ¨è¯­éŸ³è¯†åˆ«
                        if (recognition) {
                            recognition.start();
                            updateStatus('ğŸ¤ æ­£åœ¨è¯†åˆ«...');
                        } else {
                            updateStatus('é”™è¯¯ï¼šRecognition å®ä¾‹ä¸¢å¤±ã€‚');
                            console.error('[Browser Page] Recognition instance lost before start.');
                        }
                    })
                    .catch(err => {
                        clearTimeout(micPermissionTimeout);
                        console.error('[Browser Page] Microphone access error:', err);

                        let errorMsg = `æ— æ³•è®¿é—®éº¦å…‹é£ (${err.name})`;
                        if (err.name === 'NotAllowedError') {
                            errorMsg = 'éº¦å…‹é£è®¿é—®è¢«æ‹’ç»ã€‚è¯·åœ¨æµè§ˆå™¨è®¾ç½®ä¸­å…è®¸éº¦å…‹é£è®¿é—®æƒé™ã€‚';
                        } else if (err.name === 'NotFoundError') {
                            errorMsg = 'æœªæ‰¾åˆ°éº¦å…‹é£è®¾å¤‡ã€‚è¯·ç¡®ä¿éº¦å…‹é£å·²è¿æ¥ã€‚';
                        }

                        updateStatus(`é”™è¯¯: ${errorMsg}`);
                        recognition = null;
                    });
            } catch (e) {
                console.error('[Browser Page] Error calling recognition.start():', e);
                updateStatus(`å¯åŠ¨è¯†åˆ«æ—¶å‡ºé”™: ${e.message}`);
                recognition = null;
            }
        }

        function stopRecognition() {
            if (recognition) {
                console.log('[Browser Page] Stopping recognition...');
                updateStatus("æ­£åœ¨åœæ­¢è¯†åˆ«...");
                try {
                    recognition.stop();
                } catch (e) {
                    console.error('[Browser Page] Error calling recognition.stop():', e);
                    recognition = null;
                    updateStatus("åœæ­¢æ—¶å‡ºé”™ï¼Œå·²å¼ºåˆ¶é‡ç½®ã€‚");
                }
            } else {
                console.log('[Browser Page] Recognition not active, nothing to stop.');
                updateStatus("è¯†åˆ«æœªè¿è¡Œã€‚");
            }
        }

        function forceResetRecognition() {
            console.log('[Browser Page] Force resetting recognition...');
            updateStatus("å¼ºåˆ¶é‡ç½®è¯­éŸ³è¯†åˆ«...");

            // å…ˆå°è¯•åœæ­¢å½“å‰çš„è¯†åˆ«
            if (recognition) {
                try {
                    recognition.stop();
                } catch (e) {
                    console.error('[Browser Page] Error stopping recognition during reset:', e);
                }
            }

            // å¼ºåˆ¶è®¾ç½®ä¸ºnullï¼Œä¸¢å¼ƒæ‰€æœ‰åç»­ç»“æœ
            recognition = null;

            // é€šçŸ¥æœåŠ¡å™¨å·²é‡ç½®
            if (ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: 'status', message: 'reset_complete' }));
            }

            updateStatus("è¯­éŸ³è¯†åˆ«å·²é‡ç½®ï¼Œç­‰å¾…æ–°æŒ‡ä»¤ã€‚");
        }
    </script>
</body>

</html>